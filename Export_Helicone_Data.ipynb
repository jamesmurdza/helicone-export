{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vl_Vu1D6kOe8"
      },
      "outputs": [],
      "source": [
        "# Organization key\n",
        "HELICONE_API_KEY = \"sk-helicone-xxxxxxx-xxxxxxx-xxxxxxx-xxxxxxx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k75ujhFjj_l_",
        "outputId": "9f6c11e0-cec9-442c-b619-c373148c9154"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Set your API endpoint\n",
        "endpoint = \"https://www.helicone.ai/api/graphql\"\n",
        "\n",
        "# Define the GraphQL query\n",
        "query = \"\"\"\n",
        "query ExampleQuery($limit: Int, $offset: Int) {\n",
        "  heliconeRequest(\n",
        "    limit: $limit\n",
        "    offset: $offset\n",
        "  ) {\n",
        "    prompt\n",
        "    properties {\n",
        "      name\n",
        "      value\n",
        "    }\n",
        "    responseBody\n",
        "    response\n",
        "    user {\n",
        "      id\n",
        "    }\n",
        "    createdAt\n",
        "    latency\n",
        "    model\n",
        "    requestBody\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Set batch size and initial offset\n",
        "batch_size = 100\n",
        "offset = 0\n",
        "all_results = []\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {HELICONE_API_KEY}\"\n",
        "}\n",
        "\n",
        "while True:\n",
        "    # Define the variables for the query\n",
        "    variables = {\"limit\": batch_size, \"offset\": offset}\n",
        "\n",
        "    # Make the GraphQL request\n",
        "    response = requests.post(endpoint, json={\"query\": query, \"variables\": variables}, headers=headers)\n",
        "    data = response.json()[\"data\"][\"heliconeRequest\"]\n",
        "\n",
        "    # Append results to the all_results list\n",
        "    all_results.extend(data)\n",
        "\n",
        "    print(f\"Downloaded {offset+len(data)} rows...\")\n",
        "\n",
        "    # Break the loop if no more data is returned\n",
        "    if len(data) < batch_size:\n",
        "        break\n",
        "\n",
        "    # Increment the offset for the next batch\n",
        "    offset += batch_size\n",
        "\n",
        "# Save all results to a file (e.g., JSON)\n",
        "import json\n",
        "\n",
        "with open(\"helicone_results.json\", \"w\") as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "\n",
        "print(\"All results saved to helicone_results.json\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
